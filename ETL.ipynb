{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "from dateutil import parser\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"This is to load the games database onto a pandas dataframe, which allows us to manage the data more easily\"\n",
    "games=pd.read_json(\"output_steam_games.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Here, we  will check the head of the games database to see if the information is correct\"\n",
    "games.info()\n",
    "gameswna=games.dropna(axis='index',how='all')\n",
    "gameswna.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameswna.dropna(axis=0,how='any',inplace=True)\n",
    "gameswna.drop(['publisher','index','app_name','url','tags','reviews_url','specs','price','early_access'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameswna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameswna['genres']=gameswna['genres'].apply(lambda x:', '.join(x))\n",
    "gameswna['release_year'] = gameswna['release_date'].str.extract(r'(\\d{4})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameswna_dummies = gameswna['genres'].str.get_dummies(', ')\n",
    "gameswna = pd.concat([gameswna, gameswna_dummies], axis=1)\n",
    "gameswna.drop(['genres','release_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameswna.to_csv('clean_output_steam_games.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"This step is done to load the reviews database onto a pandas dataframe, which allows us to manage the data in a more efficient way\"\n",
    "with open(\"australian_user_reviews.json\",'r', encoding ='utf-8') as rw:\n",
    "    data=rw.readlines()\n",
    "db=[eval(line.strip()) for line in data]\n",
    "reviews=pd.DataFrame(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25799 entries, 0 to 25798\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   user_id   25799 non-null  object\n",
      " 1   user_url  25799 non-null  object\n",
      " 2   reviews   25799 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 604.8+ KB\n"
     ]
    }
   ],
   "source": [
    "\"Here, we  will check the head of the reviews database to see if the information is correct\"\n",
    "reviews.info()\n",
    "reviewswna=reviews.dropna(axis='index',how='all')\n",
    "reviewswna.reset_index(inplace=True)\n",
    "reviewswna.drop(['user_url','index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>[{'funny': '', 'posted': 'Posted November 5, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>js41637</td>\n",
       "      <td>[{'funny': '', 'posted': 'Posted June 24, 2014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evcentric</td>\n",
       "      <td>[{'funny': '', 'posted': 'Posted February 3.',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doctr</td>\n",
       "      <td>[{'funny': '', 'posted': 'Posted October 14, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maplemage</td>\n",
       "      <td>[{'funny': '3 people found this review funny',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                                            reviews\n",
       "0  76561197970982479  [{'funny': '', 'posted': 'Posted November 5, 2...\n",
       "1            js41637  [{'funny': '', 'posted': 'Posted June 24, 2014...\n",
       "2          evcentric  [{'funny': '', 'posted': 'Posted February 3.',...\n",
       "3              doctr  [{'funny': '', 'posted': 'Posted October 14, 2...\n",
       "4          maplemage  [{'funny': '3 people found this review funny',..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewswna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the reviews column database has more than one review, we use the explode function in order to separate every review done by the user and we store it into a new table.\n",
    "df_exploded = reviewswna.explode('reviews')\n",
    "# Afterwards, we reset the index in order to match the amount of columns, which is 59333.\n",
    "df_exploded.reset_index(inplace=True)\n",
    "# By using the drop index, we make sure to reset every single index in order for it to show us the entirety of the 59333 indexes by getting rid of the old indexes.\n",
    "df_exploded.drop('index',axis=1,inplace=True)\n",
    "# On the other hand, by using the json_normalize function, we make sure to separate the fields on the reviews column, this for us to get rid of the information we don't need or won't be using.\n",
    "df_exploded1=json_normalize(reviewswna['reviews'].explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we check the amount of rows of the new table we created.\n",
    "#df_exploded #59333 rows\n",
    "# Likewise\n",
    "#df_exploded1 #59333 rows\n",
    "# With this line we make sure to merge the split columns of the review section and the split rows of the user_id so there are no null users when merging.\n",
    "reviewswna1=pd.concat([df_exploded,df_exploded1],axis=1)\n",
    "# We proceed to get rid of the columns we wont be using towards the objective of the project and also remove any Nas that were created in the process, and also reset the indexes.\n",
    "reviewswna1.drop(['reviews','helpful','last_edited','funny'], axis=1, inplace=True)\n",
    "reviewswna1.dropna(inplace=True)\n",
    "reviewswna1.reset_index(inplace=True)\n",
    "reviewswna1.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using dateutil.parser, we create a function in order to extract the year from the posted column\n",
    "def extract_year(date_string):\n",
    "    try:\n",
    "        # We try to analyze the date with various formats\n",
    "        parsed_date = parser.parse(date_string)\n",
    "        return parsed_date.year\n",
    "    except ValueError:\n",
    "        # If this doesn't work, we try another format.\n",
    "        try:\n",
    "            parsed_date = parser.parse(date_string, fuzzy=True)\n",
    "            return parsed_date.year\n",
    "        except ValueError:\n",
    "            # If it fails again, it just returns NaT(not a time)\n",
    "            return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By applying the function we just created, we add a new column to our dataframe called year\n",
    "reviewswna1['year']=reviewswna1['posted'].apply(extract_year)\n",
    "# By using the unique function, we evaluate outliers to see why are they being created, in this case, we identify that there's an outlier with the year 2024, when we check the database,\n",
    "# we discover that the rows that have the 2024 didn't have a year on the posted column, so we proceed to delete the rows that contain the 2024 because that number was assigned by default since the field didn't have a year.\n",
    "reviewswna1['year'].unique()|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_15776\\2250573296.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reviewswna2f.drop('index',axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# We apply a filter to get rid of the 2024 values, afterwards, we proceed to reset the indexes and finally, finish cleaning the table.\n",
    "reviewswna2f=reviewswna2[reviewswna2['year']!=2024]\n",
    "reviewswna2f.reset_index(inplace=True)\n",
    "reviewswna2f.drop('index',axis=1,inplace=True)\n",
    "reviewswna2f.drop('posted',axis=1,inplace=True)\n",
    "reviewswna2f['item_id']=reviewswna2f['item_id'].astype(int)\n",
    "reviewswna2f['year']=reviewswna2f['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to assign values according to the scale\n",
    "def get_sentiment_score(text):\n",
    "    if pd.isnull(text) or text == '':\n",
    "        return 1  # Return neutral if it is empty or NaN\n",
    "    elif isinstance(text, str):\n",
    "        sentiment = sia.polarity_scores(text)\n",
    "        compound_score = sentiment['compound']\n",
    "        if compound_score >= -0.05:\n",
    "            return 2  # Good score\n",
    "        elif compound_score <= -0.05:\n",
    "            return 0  # Bad score\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 1  # Return neutral for non-string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewswna2f.drop('sentiment_analysis',axis=1,inplace=True)\n",
    "reviewswna2f['sentiment_analysis']=reviewswna2f['review'].apply(get_sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check our dataframe to see if it does have the information we need before saving it to a csv\n",
    "reviewswna2f\n",
    "# We save our dataframe into a csv database.\n",
    "reviewswna2f.to_csv('clean_output_user_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"This step is done to load the items database onto a pandas dataframe, which allows us to manage the data in a more efficient way\"\n",
    "with open(\"australian_users_items.json\",'r',encoding='utf-8') as it:\n",
    "    data=it.readlines()\n",
    "db1=[eval(line.strip()) for line in data]\n",
    "items=pd.DataFrame(db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88310 entries, 0 to 88309\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      88310 non-null  object\n",
      " 1   items_count  88310 non-null  int64 \n",
      " 2   steam_id     88310 non-null  object\n",
      " 3   user_url     88310 non-null  object\n",
      " 4   items        88310 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "\"Here, we  will check the head of the items database to see if the information is correct\"\n",
    "items.info()\n",
    "itemswna=items.dropna(axis='index',how='all')\n",
    "itemswna.reset_index(inplace=True)\n",
    "#Here we are deleting from our dataframe the columns that we don't need, in this case, we reset the indexes if there's a change on them after deleting the duplicates and Na's\n",
    "itemswna.drop(['index','steam_id','user_url','items_count'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>[{'item_id': '10', 'item_name': 'Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>js41637</td>\n",
       "      <td>[{'item_id': '10', 'item_name': 'Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evcentric</td>\n",
       "      <td>[{'item_id': '1200', 'item_name': 'Red Orchest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Riot-Punch</td>\n",
       "      <td>[{'item_id': '10', 'item_name': 'Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doctr</td>\n",
       "      <td>[{'item_id': '300', 'item_name': 'Day of Defea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                                              items\n",
       "0  76561197970982479  [{'item_id': '10', 'item_name': 'Counter-Strik...\n",
       "1            js41637  [{'item_id': '10', 'item_name': 'Counter-Strik...\n",
       "2          evcentric  [{'item_id': '1200', 'item_name': 'Red Orchest...\n",
       "3         Riot-Punch  [{'item_id': '10', 'item_name': 'Counter-Strik...\n",
       "4              doctr  [{'item_id': '300', 'item_name': 'Day of Defea..."
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemswna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsf=itemswna.explode('items')\n",
    "itemsf.reset_index(inplace=True)\n",
    "itemsf.drop('index',axis=1,inplace=True)\n",
    "itemsf2=json_normalize(itemswna['items'].explode())\n",
    "itemswnaf=pd.concat([itemsf,itemsf2],axis=1)\n",
    "itemswnaf.drop(['items','playtime_2weeks'],axis=1,inplace=True)\n",
    "itemswnaf.dropna(axis=0,how='any',inplace=True)\n",
    "itemswnaf.reset_index(inplace=True)\n",
    "itemswnaf.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itemsf #5170015 rows\n",
    "#itemsf2 #5170015 rows\n",
    "itemswnaf#5153209 rows\n",
    "itemswnaf.to_csv('clean_output_user_items.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we already have the information stored as CSV format, we will proceed by reading them and saving them into pandas dataframes.\n",
    "items=pd.read_csv('clean_output_user_items.csv')\n",
    "reviews=pd.read_csv('clean_output_user_reviews.csv')\n",
    "games=pd.read_csv('clean_output_steam_games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>playtime_forever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>20</td>\n",
       "      <td>Team Fortress Classic</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>30</td>\n",
       "      <td>Day of Defeat</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>40</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>50</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  item_id                  item_name  playtime_forever\n",
       "0  76561197970982479       10             Counter-Strike               6.0\n",
       "1  76561197970982479       20      Team Fortress Classic               0.0\n",
       "2  76561197970982479       30              Day of Defeat               7.0\n",
       "3  76561197970982479       40         Deathmatch Classic               0.0\n",
       "4  76561197970982479       50  Half-Life: Opposing Force               0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will check the first 5 rows of each database in order to see the column that will be used to merge both databases.\n",
    "games.head()\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_8640\\1446749925.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  maindf1.drop(['item_id','item_name','index'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# With this code lines what we're doing is merging the items database and the games database, in order to have the information we need in one database.\n",
    "# We also clean any na's that may appear, reset the indexes and drop the columns that we no longer need or are duplicated, finally we store the new merged database into a CSV file.\n",
    "maindf=pd.merge(items,games,how='outer',left_on='item_id',right_on='id')\n",
    "maindf1=maindf.dropna(axis=0,how='any')\n",
    "maindf1.reset_index(inplace=True)\n",
    "maindf1.drop(['item_id','item_name','index'],axis=1,inplace=True)\n",
    "maindf1.to_csv('maindb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldb=pd.read_csv('maindb.csv')\n",
    "alldbgames=alldb.drop_duplicates(subset='title')\n",
    "alldbgames.drop(['release_year','user_id','playtime_forever','Action','Adventure','Audio Production','Early Access','Photo Editing','RPG','Racing','Simulation','Software Training','Sports','Web Publishing','Utilities','Strategy','Video Production','Casual','Animation &amp; Modeling','Design &amp; Illustration','Education','Free to Play','Indie','Design &amp; Illustration','Massively Multiplayer'],axis=1,inplace=True)\n",
    "alldbgames.reset_index(inplace=True)\n",
    "alldbgames.drop('index',axis=True,inplace=True)\n",
    "alldbgames.to_csv('steam_games_devel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindb1=alldb.head(300000)\n",
    "maindb1.to_csv('maindb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
